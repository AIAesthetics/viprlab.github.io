---
layout: page
title: Research
subtitle: Final Year Projects (Undergraduate)
permalink: /research/fyp/
---
{% include nav-research.html  %}

## Final Year Projects for 2017/2018

The following are projects to be offered for undergraduate FYPs for the upcoming academic session. Do inform us directly if you have enquiries or are interested to take it up. Students working on these projects will be affiliated with our lab and will have access to our facilities (**hot-desks** are provided at the lab, but subject to availability). 
  
**Dr. Wong Lai Kuan**
- Pic2PolyArt: Transforming A Photograph into Polygon-based Geometric Art
- AmazeScape II: Transforming An Unappealing Landscape into an Amazing Landscape
- StylePotraits: Style Transfer for Portraits
- LightUpMilky: Transforming a Low-Light Image into a A Milky Way Image
- Image2Emo: What Emotion Does This Image Gives You?
- CulturalAesthetics: Influence of Culture on Aesthetics Perception
- MobiTCM: Mobile Tongue-based TCM Health Detector

**Dr. John See**
- Cal-logs: Automatic Calorie Logger based on Food Photos
- Skimlets: Finding Interesting Moments in Visual Lifelogs
- Selfr: Recommending Better Selfie-taking
- Video2Trailer: Generating Trailers from Long Video
- Visual Fashion Analytics: Finding What's In Trend
- Parvis: Visualizing Data Analytics for Carpark Surveillance

**Mr. Albert Quek**
- Augmented Reality Serious Games using Smartphones
    - Treatment of Insect Phobia
	- Interactive Story for Autistic Children
- Lifestyle Game for Smartphone
- Gesture-based Kinect Game for Visual Impaired Individuals
- Gesture-based Game Mechanics for First Person Action Game
- Virtual Reality Android based Game
- Virtual Reality for Physical Exercise

[FYP Briefing Day slides](/files/ViPrLab FYP Project Briefing - 16022017.pdf) (16/02/2017)

{::comment}
{% include imagethumbnailblock.html align="left" url="/images/aquas.png" width="120px" height="120px" padding="right" %}
Most state-of-the-art techniques for HAR have been designed to perform well under constrained and highly controlled conditions. However, these capabilities may not be easily replicable in real-world surveillance conditions (via devices such as CCTV or web cameras) where video quality may be naturally poor. We investigate new representations for recognizing human activities in adverse quality surveillance videos.
{: #proj-description}
{% include clearfloat.html prevfloat="left" %}

[Download Link](https://drive.google.com/file/d/0B_3N19NSFoBgOFVPdzg5R21hUHM)
{:/comment}
